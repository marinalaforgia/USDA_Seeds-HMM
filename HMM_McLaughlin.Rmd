---
title: "HMM McLaughlin"
author: "Marina LaForgia"
date: "8/27/2021"
output:
  word_document: default
  pdf_document: default
---

Outstanding questions: 
- If the models are going all the way to the 100th iteration, does that mean it is not converging and we should increase the number of steps?
- What is a decent cutoff for how many plots a species needs to occur in out of 80 sites for a decent estimate? 

# Markov Chain Parameter Functions

## 1. Seedbank transitions
This sets up a 2x2 matrix of seed bank transitions

c = colonization probability
g = germination probability
s = seed survival probability
r = seed production

* (1,1): 1-c -> probability of going from no seedbank in year t to no seedbank in t+1
* (1,2): c -> probability of going from no seedbank to a seedbank
* (2,1): (1-c)x(1-s)x(1-gr) -> probability of going from a seed bank to no seedbank
* (2,2): 1 - ((1-c)x(1-s)x(1-gr)) -> probability of going from a seed bank to a seedbank

```{r}

# matrix of Y transitions (Y = seedbank)
# Zt is a function of the seedbank (Y) at time t-1 and flora (x) at time t)
calculateQY = function(param) # calculate QY is a function of param; QY transition matrix 
{
  result = matrix(0,2,2) # result is a matrix of zeros with 2 columns and 2 rows
  result[1,1] = 1 - param$c # probability that plants don't colonize
  result[2,1] = (1 - param$c)*(1 - param$s)*(1 - param$g*param$r) # and the second row of the first column is (1-c) * (1-s) * (1-gF) = probability that seeds that don't colonize, dont survive, and don't germinate
  result[,2] = 1 - result[,1] # column 2 is the opposite of column one so that each row sums to 1
  return(result) # I'm still unclear on this matrix, I get that they have to sum to 1 but my probability intuition isn't that high
}

```

##  2. State transition probability matrix
Matrix of transitions Zt = (Yt-1, Xt) where Y(t-1) is the state of the seed bank in the previous year, and Xt is the state of standing flora aboveground. the three states in order are (0,0), (1,0), (1,1). where

* Zt = (0,0) = both seeds and standing flora are absent (AA)
* Zt = (1,0) = seeds are present but standing flora is absent the following year (PA)
* Zt = (1,1) = seeds are present and then standing flora is present (PP)

```{r cars}
calculateQZ = function(param) # Qz transition matrix
{
  result = matrix(0,3,3) # 3 by 3 matrix of 0s
  result[1,1] = 1 - param$c # probability seeds don't colonize
  result[2,1] = (1 - param$c)*(1 - param$s) # probability seeds don't colonize, and seeds that are there don't survive
  result[3,1] = (1 - param$c)*(1 - param$s)*(1 - param$r) # probability seeds dont colonize, seeds that are there don't survive and... wait what's r? should this be (1 - param$g*param$r)?? or just 1-param$g?
  result[,2] = (1 - result[,1])*(1 - param$g)
  result[,3] = (1 - result[,1])*param$g
  return(result)
}
```

## 3. Probability invariant of a transition matrix.  

I'm not sure what a probability invariant matrix is or what it's purpose is.
Is this the left eigenvector? the reproductive rate? Either way I think this is calculating the equilibrium state of the system

```{r}

calculatePeq = function(Q)
{
  Vmat = eigen(t(Q))$vectors
  #We look for an eigenvector whose components have the same sign and we renormalize it so that the sum makes 1
  n = dim(Q)[1]
  for (i in 1:n)
  {
    v = Vmat[,i]
    if ( all(sign(v)>=0) | all(sign(v)<=0) ) return(v/sum(v))
  }
}
```


## 4. Putting it all together

Add the object param these additional fields;

Still not sure what PZeq and PYeq, though I suspect the equilibrium state of the system and the seedbank respectively

```{r}

makeParametersCalculations = function(param)
{
  param$QY = calculateQY(param) # calculate seed bank transitions (QY)
  param$QZ = calculateQZ(param) # calculate state transition probability matrix (QZ)
  param$PZeq = calculatePeq(param$QZ) # calculate the invariant of QZ transition matrix; equilibrium state?
  param$PYeq = param$PZeq[2] + param$PZeq[3] # equilibrium state of seedbank?, this just uses the second and third value of the PZeq vector
  param$pZ0 = c(1-param$p0, param$p0*(1-param$g), param$p0*param$g) # initial distribution vector
  return(param) 
}

```

# Expectation Maximization 

Computes maximum likelihood estimators of g, c, and s

## 1. Forward algorithm for one time series 
Recursive scheme for updating the likelihood and state probabilities of the HMC going forward through time

```{r}

pZXprespast = function(X,param)  # forward algorithm for one time series
{
  tf = length(X) # time frame is length of flora
  result = matrix(0,3,tf) # result is a matrix of 0s with three rows (each state: AA, PA, PP) and tf columns
  for (t in 1:tf) # for each column (time step)
  {
    if (t == 1) pZXpast = param$pZ0 else pZXpast = t(param$QZ) %*% result[,t-1] # if it's the first time step, use the initial distribution vector, otherwise transpose the state transition probability matrix and do matrix multiplication on the result matrix from the previous time step
    result[,t] = pZXpast # paste it in for the current time step
    if (X[t] == 1) result[1:2,t] = 0 else result[3,t] = 0 # if flora observed in the current time step, the result for both rows one and two are 0 (because it's observed so it cant be absent belowground) otherwise the third row is 0)
  }
  return(result)
}
```

## 2. Backward algorithm for one time series
Recursive scheme for updating the likelihood and state probabilities of the HMC going backward in time?

```{r}

pXfuturegivenZ = function(X,param) #backward algorithm for one time series
{
  tf = length(X) # number of time steps
  result = matrix(0,3,tf) # same matrix as before
  result[,tf] = 1 # starting at 1
  for (t in tf:2) 
  {
    PZXgivenOldZ = param$QZ # take the state transition probability matrix
    if (X[t] == 1) PZXgivenOldZ[,1:2] = 0 else PZXgivenOldZ[,3] = 0 # if flora is observed in that time step, the first two columns are 0, otherwise the 3rd column is 0
    result[,t-1] = PZXgivenOldZ %*% result[,t]
  }
  return(result)
}
```

## 3. Forward Backward algorithm

Creates a function to calculate the log-likelihood and lambda coefficiencts in vector to feed into the forward backward algorithm

Recursive scheme for calculating state probabilities for any point in time, the first function is for...?

```{r}

vectForwardBackward = function(X,param) #log-likelihood and lambda coefficients for one time series; 
{
  tf = length(X) # length of the time series
  pZXpp = pZXprespast(X,param)
  pXfgZ = pXfuturegivenZ(X,param)
  pZX = pZXprespast(X,param)*pXfuturegivenZ(X,param)   #P(Zt,whole vector X)
  pZZX = array(rep(param$QZ,tf-1),c(3,3,tf-1))           #P(Zt,Zt+1,whole vector X)
  for (j in 1:3) pZZX[,j,] = pZZX[,j,]*pZXpp[,1:(tf-1)]
  for (i in 1:3) pZZX[i,,] = pZZX[i,,]*pXfgZ[,2:tf]
  pZZX[,1:2,X[2:tf] == 1] = 0
  pZZX[,3,X[2:tf] == 0] = 0
  likelihood = mean(apply(pZX,2,sum))
  result = numeric(0)
  result$ll = log(likelihood)
  result$coeffZ = pZX[,1]/likelihood
  result$coeffQ = apply(pZZX,1:2,sum)/likelihood
  return(result)
}

ForwardBackward = function(X,param) #same function extended for a N*T matrix of time series
{
  d = dim(X)
  if (length(d) == 0) return(vectForwardBackward(X,param)) else
  {
    N = d[1]
    result = numeric(0)
    llvect = apply(X,1,function(Xvect) vectForwardBackward(Xvect,param)$ll)  #N-vector,i_th component is the log-likelihood of patch i
    result$ll = sum(llvect)                                                 #sum on the N patches
    coeffZmat = apply(X,1,function(Xvect) vectForwardBackward(Xvect,param)$coeffZ) #3*N-matrix,i-th column is the lambda(z) vector of patch i
    result$coeffZ = apply(coeffZmat,1,sum)    #sum on the N patches
    coeffQarray = array(apply(X,1,function(Xvect) vectForwardBackward(Xvect,param)$coeffQ),c(3,3,N)) #3*3*N-matrix,[,,i] is the lambda(z,z') matrix of patch i
    result$coeffQ = apply(coeffQarray,1:2,sum)       #sum on the N patches
    return(result)
  }
}

```

## 4. Log Likelihood
returns the loglikelihood of the model from the forward backward algorithm

```{r}

logLikelihood = function(X,param) ForwardBackward(X,param)$ll

```


## 5. Maximization function

I start to get really lost around here

```{r}
Maximization = function(coeffQ, coeffZ, p0 = 'free', g = 'free', c = 'free', s = 'free', r = 'free')
{
  # takes into account cases of non-identifiability
  if (p0 == 'free') p0 = sum(coeffZ[2:3])/sum(coeffZ)
  if (g == 'free') g = (coeffZ[3] + sum(coeffQ[,3]))/(sum(coeffZ[2:3]) + sum(coeffQ[,2:3]))
  if (r == 'free') c2 = sum(coeffQ[3,2:3])/sum(coeffQ[3,])      #calculation of c double prime (first step)
  if (s == 'free')                                              #calculation of c prime (first step)
  {
    c1 = sum(coeffQ[2,2:3])/sum(coeffQ[2,])
    if (r == 'free') if(c2 < c1) r = 0
    if (r == 0) c1 = sum(coeffQ[2:3,2:3])/sum(coeffQ[2:3,])  
  }
  if (c == 'free')                                              #estimation of c
  {
    c0 = sum(coeffQ[1,2:3])/sum(coeffQ[1,])                     #calculation of c (first step)
    if (s == 'free') if(c1 < c0) s = 0
    if (s == 0)
    {
      if(r == 0) c0 = sum(coeffQ[,2:3])/sum(coeffQ) else c0 = sum(coeffQ[1:2,2:3])/sum(coeffQ[1:2,])
      c1 = c0
    }
    c = c0
  }
  if (s == 'free') if(c1 < c) s = 0 else s = 1 - (1-c1)/(1-c)   #estimation of s
  c1 = 1- (1-c)*(1-s)
  if (r == 'free') if(c2 < c1) r = 0 else r = 1 - (1-c2)/(1-c1) #estimation of r
  result = numeric(0)
  result$p0 = p0
  result$g = g
  result$c = c
  result$s = s
  result$r = r
  return(result)
}

```

## 6. Expected Maximization iteration

```{r}
EMiteration = function(X, param, p0 = 'free', g = 'free', c = 'free', s = 'free', r = 'free')
{
  FBresult = ForwardBackward(X,param)
  coeffZ = FBresult$coeffZ
  coeffQ = FBresult$coeffQ
  newparam = Maximization(coeffQ,coeffZ,p0,g,c,s,r)
  newparam = makeParametersCalculations(newparam)
  EMresult = numeric(0)
  EMresult$ll = FBresult$ll
  EMresult$newparam = newparam
  return(EMresult)
}

```

## 7. Expected maximization estimation

```{r}
EMestimation = function(X, nIterations = 100, precision = 10^(-5), p0 = 'free', g = 'free', c = 'free', s = 'free', r = 'free')
{
  alwaysSeedSurvival = FALSE
  if (s == 1 | c == 1 | (g == 1 & r == 1))
  {
    alwaysSeedSurvival = TRUE
    if (r == 'free') print('r non identifiable')
    r = 1
    if (s == 'free') print('s non identifiable')
    s = 1
  }
  if (p0 == 1 & alwaysSeedSurvival)
  {
    if (c == 'free') print('c non identifiable')
    c = 1
  }
  if (g == 1)
  {
    if (s == 'free' & r == 'free') print('r non identifiable from s')
    r = 0
  }
  lllist = rep(0,nIterations)
  p0list = rep(0,nIterations)
  glist = rep(0,nIterations)
  clist = rep(0,nIterations)
  slist = rep(0,nIterations)
  rlist = rep(0,nIterations)
  param = numeric(0)
  if (p0 == 'free') param$p0 = runif(1) else param$p0 = p0
  if (g == 'free') param$g = runif(1) else param$g = g
  if (c == 'free') param$c = runif(1) else param$c = c
  if (s == 'free') param$s = runif(1) else param$s = s
  if (r == 'free') param$r = runif(1) else param$r = r
  param = makeParametersCalculations(param)
  oldLogLikelihood = -Inf
  for (k in 1:nIterations)
  {
    print(t(param[c('p0','g','c','s','r')]))
    EMresult = EMiteration(X,param,p0,g,c,s,r)
    logLikelihood = EMresult$ll
    lllist[k] = logLikelihood
    p0list[k] = param$p0
    glist[k] = param$g
    clist[k] = param$c
    slist[k] = param$s
    rlist[k] = param$r
    print(logLikelihood)
    if(logLikelihood < oldLogLikelihood + precision) break
    print(k)
    oldLogLikelihood = logLikelihood
    param = EMresult$newparam
  }
  EMresult = numeric(0)
  EMresult$lllist = lllist
  EMresult$p0list = p0list
  EMresult$glist = glist
  EMresult$clist = clist
  EMresult$slist = slist
  EMresult$rlist = rlist
  EMresult$ll = logLikelihood
  EMresult$param = param
  return(EMresult)
}


```

# Grassland (McLaughlin)

##1. Data prep
* what is a good cut off for number of plots a species must be in to get decent estimates? I cut it off at 8 at the moment.

```{r, echo = F}
library(ggplot2)
library(plyr)
library(tidyverse)
trait <- read.csv("/Users/Marina/Google Drive/02_McLaughlin_80Sites_Organized/Modified_CombinedFiles/McL_80SitesSpeciesTraits_012615.csv")
mcl <- read.csv("/Users/Marina/Google Drive/02_McLaughlin_80Sites_Organized/Data-Storage-Files/Core_Community_Data2019.csv")
#mcl <- filter(mcl, Species_Name != "Bare", Species_Name != "Rock", Species_Name != "Juncus sp.")
mcl <- filter(mcl, Species_Name %in% trait[trait$Annual.Perennial == "Annual",]$Species_Name)
mcl <- ddply(mcl, .(Site, Year, Species_Name), summarize, PA = 1)
mcl <- pivot_wider(mcl, names_from = "Year", values_from = "PA")
mcl <- as.data.frame(mcl)
mcl[is.na(mcl)] <- 0

species.list <- list()

for(i in unique(mcl$Species_Name)) {
  tmp <- filter(mcl, Species_Name == i)
  tmp <- tmp[,-c(1:2)]
  tmp <- tmp[ , sort(colnames(tmp))]
  if(nrow(tmp) > 9) species.list[[i]] <- tmp # for now I got rid of species that were present in less than 8 sites throughout the entire time series, 167 species without down to 103, which is a lot, check with POC & Roger about a good cut-off
}
# 
# df <- data.frame(names = NA, obs = NA)
# 
# for(i in names(species.list)) {
#   df <- data.frame(rbind(df, c(names = i, obs = nrow(species.list[[i]]))))
# }
# df$obs <- as.numeric(as.character(df$obs))

saveRDS(species.list, "McL_Species-List-for-HMM_Site.RDS")
```

##2. HMM on McLaughlin
* Why does n = 5 and why print it out 5 times? 
* Why print(logLikelihood(X, trueParam)) twice? this is the loglikelihood of the data given the true params
* It's iterative in that it is going through the EM process of estimating these parameters given all the algorithms specified above, then updating the loglikelihood and comparing to the previous model, once it reaches a certain cutoff, it stops (hopefully before it gets to 100), then is starts over (it does this 5 times, for each n? k?) not from the previous estimates but from what?
* Are the last estimates of the params the "final" estimates given the best log-likelihood?
* What happens if it gets through all 100 time steps, it just stops there even if it wasn't maximized right? Can we trust those values?
```{r, eval = F}

# starting values. might not necessarily help much to change these, but we can try
trueParam = numeric(0) #object grouping together the parameters and other quantities which depend on them.
trueParam$c = 0.2      #colonization rate
trueParam$g = 0.5      #germination rate (sigma)
trueParam$r = 1        #reproductive rate (phi) keep this at 1 (if a seed germinates and survives to flower, we assume it produces a seed)
trueParam$s = 0.5      #seed survival
trueParam$p0 = 0.5     #initial state of the seed bank (probability that there were seeds in the soil the year before the first obs of existing flora)

trueParam = makeParametersCalculations(trueParam)

species.list <- readRDS("McL_Species-List-for-HMM_Site.RDS") # list; each object is a dataframe of PA data for a single species where each row is a site and each column is a year


mcl.df <- expand.grid(Species_Name = names(species.list), p0 = NA, g = NA, c = NA, s = NA, r = NA) # empty df to fill with rates


# Took about 20 minutes or so
for(j in names(species.list)){ # for each species
  X = as.matrix(species.list[[j]]) # use their time series PA data
  n = 5 # why n = 5?
  p0Results = rep(0,n)
  gResults = rep(0,n)
  cResults = rep(0,n)
  sResults = rep(0,n)
  rResults = rep(0,n)
  llResults = rep(0,n)
  lltrueParam = rep(0,n)
  
  for (i in 1:n) {
    for (k in 1:5) print(i) # I don't understand what's going on here, why print it 5 times?
    print(logLikelihood(X, trueParam)) # print the log-likelihood given the "true params"
    EMresult = EMestimation(X, r = 1) # update the model params, stop when new log likelihood is lower than the old log likelihood plus some precision 
    print(logLikelihood(X, trueParam)) # print the log-likelihood given the "true params"; why is this on here twice?
    # fill in results with new params from the best log likelihood model
    p0Results[i] = EMresult$param$p0 # initial seed bank prob
    gResults[i] = EMresult$param$g # germ
    cResults[i] = EMresult$param$c #col
    sResults[i] = EMresult$param$s #surv
    rResults[i] = EMresult$param$r #prod
    llResults[i] = EMresult$ll # log-likelihood
    lltrueParam[i] = logLikelihood(X,trueParam) # log likelihood of x given "true" parameters
  }

  # here I assumed that the last estimated parameters, were what the model converged on but I'm not sure that's correct?
  mcl.df[mcl.df$Species_Name == j,]$p0 <- EMresult$param$p0
  mcl.df[mcl.df$Species_Name == j,]$g <- EMresult$param$g
  mcl.df[mcl.df$Species_Name == j,]$c <- EMresult$param$c
  mcl.df[mcl.df$Species_Name == j,]$s <- EMresult$param$s
  mcl.df[mcl.df$Species_Name == j,]$r <- EMresult$param$r
  
}

```


##3. Graphical relationships

```{r, echo = F}
#trait <- read.csv("/Users/Marina/Google Drive/02_McLaughlin_80Sites_Organized/Modified_CombinedFiles/McL_80SitesSpeciesTraits_012615.csv")
# mcl.df <- merge(mcl.df, trait[,c(1,3,17,18,19)], by = "Species_Name", all.y = F)
# mcl.df <- filter(mcl.df, Annual.Perennial == "Annual")
# mcl.df$FunGroup <- paste(mcl.df$Native.Exotic, mcl.df$Grass.Forb.Shrub)

mcl.df <- readRDS("POC_HMM_McL.RDS")
ggplot(mcl.df, aes(x = s, y = c, col = Grass.Forb.Shrub, group = Grass.Forb.Shrub)) +
  geom_point() +
  geom_smooth(method = "lm", formula = y ~ x)

ggplot(mcl.df, aes(x = Grass.Forb.Shrub, y = c)) +
  geom_boxplot() +
  facet_wrap(~Native.Exotic)

ggplot(mcl.df, aes(x = Grass.Forb.Shrub, y = s)) +
  geom_boxplot() +
  facet_wrap(~Native.Exotic)

```

# Desert (Tumamoc Hill)

##1. Data Prep

```{r, echo = F}

sd <- read.csv("/Users/Marina/Documents/USDA-PostDoc/Projects/Sonoran-Desert/CensusData.csv")

remove <- c("CRsp", # removing species without precise IDs
            "DA-SP",
            "eriog",
            "Eriog",
            "ERIOG",
            "LO-AS",
            "LOsp",
            "PHsp",
            "PLsp",
            "plsp",
            "ersp",
            "crsp"
            )

sd <-  filter(sd, !species %in% remove)
sd.sum <- ddply(sd, .(Year, plot.habitat.replicate, species), summarize, PA = 1)

sd.sum <- pivot_wider(sd.sum, names_from = "Year", values_from = "PA")
sd.sum <- as.data.frame(sd.sum)
sd.sum[is.na(sd.sum)] <- 0

species.list <- list()

for(i in unique(sd.sum$species)) {
  tmp <- filter(sd.sum, species == i)
  tmp <- tmp[,-c(1:2)]
  tmp <- tmp[ , sort(colnames(tmp))]
  if(nrow(tmp) > 9) species.list[[i]] <- tmp # apparently I used the same cut off here, have to look into that more closely
}

```


##2. HMM on Sonoran Desert

```{r, eval = F}

trueParam = numeric(0) #object grouping together the parameters and other quantities which depend on them.
trueParam$c = 0.2      #colonization rate
trueParam$g = 0.5      #germination rate (sigma)
trueParam$r = 1        #reproductive rate (phi)
trueParam$s = 0.5      #seed survival
trueParam$p0 = 0.5     #initial state of the seed bank (probability that there were seeds in the soil the year before the first obs of existing flora)

trueParam = makeParametersCalculations(trueParam)

species.list <- readRDS("SD_Species-List-for-HMM_Site.RDS") 

sd.df <- expand.grid(Species_Name = names(species.list), p0 = NA, g = NA, c = NA, s = NA, r = NA) # empty df to fill with rates

for(j in names(species.list)){ # for each species
  X = as.matrix(species.list[[j]]) # use their time series PA data
  n = 5 # why n = 5?
  p0Results = rep(0,n)
  gResults = rep(0,n)
  cResults = rep(0,n)
  sResults = rep(0,n)
  rResults = rep(0,n)
  llResults = rep(0,n)
  lltrueParam = rep(0,n)
  
  for (i in 1:n) {
    for (k in 1:5) print(i) # I don't understand what's going on here, why print it 5 times?
    print(logLikelihood(X, trueParam)) # print the log-likelihood given the "true params"
    EMresult = EMestimation(X, r = 1) # update the model params, stop when new log likelihood is lower than the old log likelihood plus some precision 
    print(logLikelihood(X, trueParam)) # print the log-likelihood given the "true params"; why is this on here twice?
    # fill in results with new params from the best log likelihood model
    p0Results[i] = EMresult$param$p0 # initial seed bank prob
    gResults[i] = EMresult$param$g # germ
    cResults[i] = EMresult$param$c #col
    sResults[i] = EMresult$param$s #surv
    rResults[i] = EMresult$param$r #prod
    llResults[i] = EMresult$ll # log-likelihood
    lltrueParam[i] = logLikelihood(X,trueParam) # log likelihood of x given "true" parameters
  }

  sd.df[sd.df$Species_Name == j,]$p0 <- EMresult$param$p0
  sd.df[sd.df$Species_Name == j,]$g <- EMresult$param$g
  sd.df[sd.df$Species_Name == j,]$c <- EMresult$param$c
  sd.df[sd.df$Species_Name == j,]$s <- EMresult$param$s
  sd.df[sd.df$Species_Name == j,]$r <- EMresult$param$r
  
}

```

##3. Graphical Relationaships

```{r, echo = F}
library(ggplot2)
sd.df <- readRDS("SD_HMM.RDS")

ggplot(sd.df, aes(x = s, y = c)) +
  geom_point() +
  geom_smooth(method = "lm", formula = y ~ x)

# compare with actual seed survival
surv <- read.csv("/Users/Marina/Documents/USDA-PostDoc/Projects/Sonoran-Desert/SD_Seed-survival.csv")
surv <- merge(surv, sd.df[,c(1,5)], by.x = "Species", by.y = "Species_Name", all.y = F)

ggplot(surv, aes(x = Surv, y = s)) +
  geom_point() +
  geom_smooth(method = "lm") +
  geom_label(aes(label = Species)) +
  labs(x = "Seed survival (Fall)", y = "HMM-predicted seed survival") +
  geom_abline(slope = 1, intercept = 0)

```


# System comparison

```{r, echo = F}

sd.df$site <- "Desert"
mcl.df$site <- "Grassland"

gd <- rbind(sd.df, mcl.df[,c(1:6,12)])

ggplot(gd, aes(x = s, y = c, col = site, group = site)) +
  geom_point() +
  geom_smooth(method = "lm", formula = y ~ x) 

ggplot(gd, aes(x = site, y = c)) +
  geom_boxplot() 

ggplot(gd, aes(x = site, y = s)) +
  geom_boxplot()

# it's ok that we don;t see a tradeoff between g and s in the desert, g is the probability that a single seed is going to germinate at any given time, not the observed germination fraction that came out of the demographic data

```

# Climate Change
Split up the time series to look at whether changes in climate (declining rainfall) in the grassland dataset has contributed to shifts in survival/colonization behavior

2000-2010: higher av rainfall, lower variability
2011-2019: lower av rainfall, higher variability

##1. HMM on 1st half of time series
```{r, echo = F}

mcl.df.beg <- expand.grid(Species_Name = names(species.list), p0 = NA, g = NA, c = NA, s = NA, r = NA) # empty df to fill with rates

for(j in names(species.list)){ # for each species
  X = as.matrix(species.list[[j]][,1:10]) # use their time series PA data
  n = 5 # why n = 5?
  p0Results = rep(0,n)
  gResults = rep(0,n)
  cResults = rep(0,n)
  sResults = rep(0,n)
  rResults = rep(0,n)
  llResults = rep(0,n)
  lltrueParam = rep(0,n)
  
  for (i in 1:n) {
    for (k in 1:5) print(i) # I don't understand what's going on here, why print it 5 times?
    print(logLikelihood(X, trueParam)) # print the log-likelihood given the "true params"
    EMresult = EMestimation(X, r = 1) # update the model params, stop when new log likelihood is lower than the old log likelihood plus some precision 
    print(logLikelihood(X, trueParam)) # print the log-likelihood given the "true params"; why is this on here twice?
    # fill in results with new params from the best log likelihood model
    p0Results[i] = EMresult$param$p0 # initial seed bank prob
    gResults[i] = EMresult$param$g # germ
    cResults[i] = EMresult$param$c #col
    sResults[i] = EMresult$param$s #surv
    rResults[i] = EMresult$param$r #prod
    llResults[i] = EMresult$ll # log-likelihood
    lltrueParam[i] = logLikelihood(X,trueParam) # log likelihood of x given "true" parameters
  }

  mcl.df.beg[mcl.df.beg$Species_Name == j,]$p0 <- EMresult$param$p0
  mcl.df.beg[mcl.df.beg$Species_Name == j,]$g <- EMresult$param$g
  mcl.df.beg[mcl.df.beg$Species_Name == j,]$c <- EMresult$param$c
  mcl.df.beg[mcl.df.beg$Species_Name == j,]$s <- EMresult$param$s
  mcl.df.beg[mcl.df.beg$Species_Name == j,]$r <- EMresult$param$r
  
}
```

##2. HMM on 2nd half of time series

```{r, echo = F}
mcl.df.end <- expand.grid(Species_Name = names(species.list), p0 = NA, g = NA, c = NA, s = NA, r = NA) # empty df to fill with rates


for(j in names(species.list)){ # for each species
  X = as.matrix(species.list[[j]][,11:20]) # use their time series PA data
  n = 5 # why n = 5?
  p0Results = rep(0,n)
  gResults = rep(0,n)
  cResults = rep(0,n)
  sResults = rep(0,n)
  rResults = rep(0,n)
  llResults = rep(0,n)
  lltrueParam = rep(0,n)
  
  for (i in 1:n) {
    for (k in 1:5) print(i) # I don't understand what's going on here, why print it 5 times?
    print(j)
    print(logLikelihood(X, trueParam)) # print the log-likelihood given the "true params"
    EMresult = EMestimation(X, r = 1) # update the model params, stop when new log likelihood is lower than the old log likelihood plus some precision 
    print(logLikelihood(X, trueParam)) # print the log-likelihood given the "true params"; why is this on here twice?
    # fill in results with new params from the best log likelihood model
    p0Results[i] = EMresult$param$p0 # initial seed bank prob
    gResults[i] = EMresult$param$g # germ
    cResults[i] = EMresult$param$c #col
    sResults[i] = EMresult$param$s #surv
    rResults[i] = EMresult$param$r #prod
    llResults[i] = EMresult$ll # log-likelihood
    lltrueParam[i] = logLikelihood(X,trueParam) # log likelihood of x given "true" parameters
  }

  # here I assumed that the last estimated parameters, were what the model converged on but I'm not sure that's correct?
  mcl.df.end[mcl.df.end$Species_Name == j,]$p0 <- EMresult$param$p0
  mcl.df.end[mcl.df.end$Species_Name == j,]$g <- EMresult$param$g
  mcl.df.end[mcl.df.end$Species_Name == j,]$c <- EMresult$param$c
  mcl.df.end[mcl.df.end$Species_Name == j,]$s <- EMresult$param$s
  mcl.df.end[mcl.df.end$Species_Name == j,]$r <- EMresult$param$r
  
}

```

##3. Graphical relationships

```{r, echo = F}
mcl.df.beg$tf <- "2000-2010"
mcl.df.end$tf <- "2011-2019"

mcl.df.split <- rbind(mcl.df.beg, mcl.df.end)

ggplot(mcl.df.split, aes(x = s, y = c, group = tf, col = tf)) +
  geom_point() +
  geom_smooth(method = "lm", formula = y ~ x)

mcl.df.split <- merge(mcl.df.split, trait[,c(1,3,17,18,19)], by = "Species_Name", all.y = F)
mcl.df.split <- filter(mcl.df.split, Annual.Perennial == "Annual")
mcl.df.split$FunGroup <- paste(mcl.df.split$Native.Exotic, mcl.df.split$Grass.Forb.Shrub)

ggplot(mcl.df.split, aes(x = s, y = c, group = tf, col = tf)) +
  geom_point() +
  geom_smooth(method = "lm", formula = y ~ x) +
  facet_wrap(~FunGroup)

ggplot(mcl.df.split, aes(x = s, y = c, group = Species_Name)) +
ggforce::geom_link2(aes(group = Species_Name, color = tf), size = 1, n = 500, lineend = "round") +
  facet_wrap(~FunGroup)

# Colonization seems to decrease but seed survival is not necessarily increasing to compensate... next steps: adding seed traits!

ggplot(mcl.df.split, aes(y = s, x = tf)) +
  geom_boxplot() +
  facet_wrap(~FunGroup)

ggplot(mcl.df.split, aes(y = c, x = tf)) +
  geom_boxplot() +
  facet_wrap(~FunGroup)

```